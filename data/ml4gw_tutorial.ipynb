{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code directly from [`ml4gw`](https://github.com/ML4GW/ml4gw) Tutorial (https://github.com/ML4GW/ml4gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired duration of time-domain waveform\n",
    "waveform_duration = 8\n",
    "# Sample rate of all the data we'll be using today\n",
    "sample_rate = 2048\n",
    "\n",
    "# Define minimum, maximum, and reference frequencies\n",
    "f_min = 10\n",
    "f_max = 1024\n",
    "f_ref = 20\n",
    "\n",
    "nyquist = sample_rate / 2\n",
    "num_samples = int(waveform_duration * sample_rate)\n",
    "num_freqs = num_samples // 2 + 1\n",
    "\n",
    "# Create an array of frequency values at which to generate our waveform\n",
    "# At the moment, only frequency-domain approximants have been implemented\n",
    "frequencies = torch.linspace(0, nyquist, num_freqs).to(device)\n",
    "freq_mask = (frequencies >= f_min) * (frequencies < f_max).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.distributions import PowerLaw, Sine, Cosine, DeltaFunction\n",
    "from torch.distributions import Uniform\n",
    "\n",
    "# On CPU, keep the number of waveforms around 100. On GPU, you can go higher\n",
    "num_waveforms = 1000\n",
    "\n",
    "# Create a dictionary of parameter distributions\n",
    "param_dict = {\n",
    "    \"chirp_mass\": PowerLaw(((1/4)**(3/5) * 20), ((1/4)**(3/5) * 800), -2.35),\n",
    "    \"mass_ratio\": DeltaFunction(1),\n",
    "    \"chi1\": DeltaFunction(0),\n",
    "    \"chi2\": DeltaFunction(0),\n",
    "    \"distance\": PowerLaw(100, 1000, 2),\n",
    "    \"phic\": DeltaFunction(0),\n",
    "    \"inclination\": Sine(),\n",
    "}\n",
    "\n",
    "# param_dict = {\n",
    "#     \"chirp_mass\": PowerLaw(10, 100, -2.35),\n",
    "#     \"mass_ratio\": Uniform(0.125, 0.999),\n",
    "#     \"chi1\": Uniform(-0.999, 0.999),\n",
    "#     \"chi2\": Uniform(-0.999, 0.999),\n",
    "#     \"distance\": PowerLaw(100, 1000, 2),\n",
    "#     \"phic\": DeltaFunction(0),\n",
    "#     \"inclination\": Sine(),\n",
    "# }\n",
    "\n",
    "# And then sample from each of those distributions\n",
    "params = {\n",
    "    k: v.sample((num_waveforms,)).to(device) for k, v in param_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross polarization frequency shape: torch.Size([1000, 8112]), Plus polarization frequency shape: torch.Size([1000, 8112])\n"
     ]
    }
   ],
   "source": [
    "from ml4gw.waveforms import IMRPhenomD\n",
    "\n",
    "approximant = IMRPhenomD().to(device)\n",
    "\n",
    "# Calling the approximant with the frequency array, reference frequency, and waveform parameters\n",
    "# returns the cross and plus polarizations\n",
    "hc_f, hp_f = approximant(f=frequencies[freq_mask], f_ref=f_ref, **params)\n",
    "print(f\"Cross polarization frequency shape: {hc_f.shape}, Plus polarization frequency shape: {hp_f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross polarization strain shape: torch.Size([1000, 16384]), Plus polarization strain shape: torch.Size([1000, 16384])\n"
     ]
    }
   ],
   "source": [
    "# create spectrum of frequencies, initially filled with zeros,\n",
    "# with a delta_f such that after we fft to time domain the duration\n",
    "# of the waveform will be waveform_duration\n",
    "shape = (hc_f.shape[0], num_freqs)\n",
    "hc_spectrum = torch.zeros(shape, dtype=hc_f.dtype, device=device)\n",
    "hp_spectrum = torch.zeros(shape, dtype=hc_f.dtype, device=device)\n",
    "\n",
    "# fill the spectrum with the\n",
    "# hc and hp values at the specified frequencies\n",
    "hc_spectrum[:, freq_mask] = hc_f\n",
    "hp_spectrum[:, freq_mask] = hp_f\n",
    "\n",
    "# now, irfft and scale the waveforms by sample_rate\n",
    "hc, hp = torch.fft.irfft(hc_spectrum), torch.fft.irfft(hp_spectrum)\n",
    "hc *= sample_rate\n",
    "hp *= sample_rate\n",
    "\n",
    "# The coalescence point is placed at the right edge, so shift it to\n",
    "# give some room for ringdown\n",
    "ringdown_duration = 0.5\n",
    "ringdown_size = int(ringdown_duration * sample_rate)\n",
    "hc = torch.roll(hc, -ringdown_size, dims=-1)\n",
    "hp = torch.roll(hp, -ringdown_size, dims=-1)\n",
    "print(f\"Cross polarization strain shape: {hc.shape}, Plus polarization strain shape: {hp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform shape: torch.Size([1000, 2, 16384])\n"
     ]
    }
   ],
   "source": [
    "from ml4gw.gw import get_ifo_geometry, compute_observed_strain\n",
    "\n",
    "# Define probability distributions for sky location and polarization angle\n",
    "dec = Cosine()\n",
    "psi = Uniform(0, torch.pi)\n",
    "phi = Uniform(-torch.pi, torch.pi)\n",
    "\n",
    "# The interferometer geometry for V1 and K1 are also in ml4gw\n",
    "ifos = [\"H1\", \"L1\"]\n",
    "tensors, vertices = get_ifo_geometry(*ifos)\n",
    "\n",
    "# Pass the detector geometry, along with the polarizations and sky parameters,\n",
    "# to get the observed strain\n",
    "waveforms = compute_observed_strain(\n",
    "    dec=dec.sample((num_waveforms,)).to(device),\n",
    "    psi=psi.sample((num_waveforms,)).to(device),\n",
    "    phi=phi.sample((num_waveforms,)).to(device),\n",
    "    detector_tensors=tensors.to(device),\n",
    "    detector_vertices=vertices.to(device),\n",
    "    sample_rate=sample_rate,\n",
    "    cross=hc,\n",
    "    plus=hp,\n",
    ")\n",
    "print(f\"Waveform shape: {waveforms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Spectral Density shape: torch.Size([2, 2049])\n"
     ]
    }
   ],
   "source": [
    "from ml4gw.transforms import SpectralDensity\n",
    "import h5py\n",
    "\n",
    "fftlength = 2\n",
    "spectral_density = SpectralDensity(\n",
    "    sample_rate=sample_rate,\n",
    "    fftlength=fftlength,\n",
    "    overlap=None,\n",
    "    average=\"median\",\n",
    ").to(device)\n",
    "\n",
    "# This is H1 and L1 background data from the O3 Observation run\n",
    "background_file = \"/data/p_dsi/ligo/chattec-dgx01/chattec/LIGO/ligo_data/ml4gw_data_test/background-1240658942-9110.hdf5\"\n",
    "with h5py.File(background_file, \"r\") as f:\n",
    "    background = [torch.Tensor(f[ifo][:]) for ifo in ifos]\n",
    "    background = torch.stack(background).to(device)\n",
    "\n",
    "# Note cast to double\n",
    "psd = spectral_density(background.double())\n",
    "print(f\"Power Spectral Density shape: {psd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.gw import compute_ifo_snr, compute_network_snr\n",
    "\n",
    "# Note need to interpolate\n",
    "if psd.shape[-1] != num_freqs:\n",
    "    # Adding dummy dimensions for consistency\n",
    "    while psd.ndim < 3:\n",
    "        psd = psd[None]\n",
    "    psd = torch.nn.functional.interpolate(\n",
    "        psd, size=(num_freqs,), mode=\"linear\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4gw.gw import reweight_snrs\n",
    "\n",
    "target_snrs = PowerLaw(12, 100, -3).sample((num_waveforms,)).to(device)\n",
    "# Each waveform will be scaled by the ratio of its target SNR to its current SNR\n",
    "waveforms = reweight_snrs(\n",
    "    responses=waveforms,\n",
    "    target_snrs=target_snrs,\n",
    "    psd=psd,\n",
    "    sample_rate=sample_rate,\n",
    "    highpass=f_min,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background samples shape: torch.Size([2000, 2, 39936])\n"
     ]
    }
   ],
   "source": [
    "from ml4gw.dataloading import Hdf5TimeSeriesDataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Length of data used to estimate PSD\n",
    "psd_length = 16\n",
    "psd_size = int(psd_length * sample_rate)\n",
    "\n",
    "# Length of filter. A segment of length fduration / 2\n",
    "# will be cropped from either side after whitening\n",
    "fduration = 2\n",
    "\n",
    "# Length of window of data we'll feed to our network\n",
    "kernel_length = 1.5\n",
    "kernel_size = int(1.5 * sample_rate)\n",
    "\n",
    "# Total length of data to sample\n",
    "window_length = psd_length + fduration + kernel_length\n",
    "\n",
    "fnames = list(Path(\"/data/p_dsi/ligo/chattec-dgx01/chattec/LIGO/ligo_data/ml4gw_data_test\").iterdir())\n",
    "dataloader = Hdf5TimeSeriesDataset(\n",
    "    fnames=fnames,\n",
    "    channels=ifos,\n",
    "    kernel_size=int(window_length * sample_rate),\n",
    "    batch_size=2\n",
    "    * num_waveforms,  # Grab twice as many background samples as we have waveforms\n",
    "    batches_per_epoch=1,\n",
    "    coincident=False,\n",
    ")\n",
    "\n",
    "background_samples = [x for x in dataloader][0].to(device)\n",
    "print(f\"Background samples shape: {background_samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSD shape: torch.Size([2000, 2, 2049])\n",
      "Kernel shape: torch.Size([2000, 2, 7168])\n",
      "Whitened kernel shape: torch.Size([2000, 2, 3072])\n"
     ]
    }
   ],
   "source": [
    "from ml4gw.transforms import Whiten\n",
    "\n",
    "whiten = Whiten(\n",
    "    fduration=fduration, sample_rate=sample_rate, highpass=f_min\n",
    ").to(device)\n",
    "\n",
    "# Create PSDs using the first psd_length seconds of each sample\n",
    "# with the SpectralDensity module we defined earlier\n",
    "psd = spectral_density(background_samples[..., :psd_size].double())\n",
    "print(f\"PSD shape: {psd.shape}\")\n",
    "\n",
    "# Take everything after the first psd_length as our input kernel\n",
    "kernel = background_samples[..., psd_size:]\n",
    "# And whiten using our PSDs\n",
    "whitened_kernel = whiten(kernel, psd)\n",
    "print(f\"Kernel shape: {kernel.shape}\")\n",
    "print(f\"Whitened kernel shape: {whitened_kernel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = int(fduration / 2 * sample_rate)\n",
    "injected = kernel.detach().clone()\n",
    "# Inject waveforms into every other background sample\n",
    "injected[::2, :, pad:-pad] += waveforms[..., -kernel_size:]\n",
    "# And whiten with the same PSDs as before\n",
    "whitened_injected = whiten(injected, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(len(injected))\n",
    "y[::2] = 1\n",
    "with h5py.File(\"validation_dataset.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"X\", data=whitened_injected.cpu())\n",
    "    f.create_dataset(\"y\", data=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
